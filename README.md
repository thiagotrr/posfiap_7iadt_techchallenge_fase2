# üèÜ Tech Challenge Fase 2 - P√≥s Tech IA para Devs (posfiap_7iadt_techchallenge_fase2)

## üéØ Projeto Fase 2: Otimiza√ß√£o de Modelos de Diagn√≥stico
O hospital precisa melhorar a precis√£o e efici√™ncia dos modelos de diagn√≥stico desenvolvidos na Fase 1. O desafio √© utilizar algoritmos gen√©ticos para otimizar os hiperpar√¢metros desses modelos, al√©m de incorporar capacidades iniciais de processamento de linguagem natural por meio de LLMs para melhorar a interpretabilidade dos resultados para os profissionais de sa√∫de.

## üõ†Ô∏è Instala√ß√£o e execu√ß√£o
1.  **Clone o reposit√≥rio:**
    ```bash
    git clone <URL_DO_REPOSITORIO>
    ```
2.  **Instale as depend√™ncias** a partir do `requirements.txt`:
    ```bash
    pip install -r requirements.txt
    ```
3.  **Execute a aplica√ß√£o** a partir da raiz do projeto:
    ```bash
    python main.py
    ```
4.  **Acesse a API** no seu navegador:
    -   **Swagger UI**: [http://localhost:8181/docs](http://localhost:8181/docs) Êé•Âè£
    -   **OpenAPI JSON**: [http://localhost:8181/openapi.json](http://localhost:8181/openapi.json) üìÑ

## ‚ú® Features Projeto Fase 2

Este projeto expande as capacidades do modelo de diagn√≥stico da Fase 1, introduzindo novas funcionalidades para treinamento, otimiza√ß√£o e rastreabilidade.

### üöÄ Treinamento e Otimiza√ß√£o do Modelo

- **Treinamento via API**: Execute o treinamento de um novo modelo `RandomForest` com `SMOTE` a qualquer momento atrav√©s do endpoint `/treinar_modelo`.
- **Otimiza√ß√£o com Algoritmo Gen√©tico**: Utilize o endpoint `/otimizar_modelo` para otimizar os hiperpar√¢metros do modelo. O processo utiliza um algoritmo gen√©tico para encontrar a melhor combina√ß√£o de par√¢metros, maximizando a performance.

### üîó Identificador √önico e Rastreabilidade

- Cada processo de **treinamento** ou **otimiza√ß√£o** gera um **identificador √∫nico hexadecimal**.
- Esse `id` cria um v√≠nculo direto e inequ√≠voco entre o **modelo treinado** (arquivo `.joblib`) e seu respectivo **arquivo de log**, garantindo total rastreabilidade dos artefatos gerados.

### ‚¨áÔ∏è Download de Artefatos

- **Acesso direto aos modelos e logs**: Ap√≥s o treinamento ou otimiza√ß√£o, utilize os endpoints `/modelo/{id_hex}` e `/log/{id_hex}` para baixar os arquivos gerados.
- Facilita a an√°lise de performance, o reuso de modelos e a auditoria do processo.

## ‚è™ Recap Fase 1
### üìä Dataset: Indian Liver Patient Dataset
A morte por cirrose hep√°tica continua a aumentar, devido ao aumento nas taxas de consumo de √°lcool, infec√ß√µes cr√¥nicas por hepatite e doen√ßas hep√°ticas relacionadas √† obesidade. Apesar da alta mortalidade dessa doen√ßa, as doen√ßas do f√≠gado n√£o afetam todas as subpopula√ß√µes de forma igual. A detec√ß√£o precoce da patologia √© determinante para o desfecho dos pacientes, mas as pacientes do sexo feminino parecem ser marginalizadas quando se trata do diagn√≥stico precoce de doen√ßas hep√°ticas.

O conjunto de dados √© composto por 584 registros de pacientes coletados no nordeste de Andhra Pradesh, na √çndia. A tarefa de predi√ß√£o consiste em determinar se um paciente sofre de doen√ßa hep√°tica com base em informa√ß√µes sobre diversos marcadores bioqu√≠micos, incluindo albumina e outras enzimas necess√°rias para o metabolismo.

### üß† Modelo Final: Random Forest com SMOTE

**Link do Notebook**: [Google Colab](https://colab.research.google.com/drive/1hcM9gq6GKSIyd4yXzhrtj6E1O54fqEPE?usp=sharing) üìù

Considerando a finalidade acad√™mica, e sabedores da sensibilidade em modelos voltados para √°rea de sa√∫de, tentamos duas √∫ltimas a√ß√µes:
    - Aplicar o `SMOTE` com objetivo de mitigar o desbalanceamento das classes.
    - Utilizar o `StratifiedKFold`, que performa melhor com dados bin√°rios.

### üìà Conclus√µes Fase 1
Os resultados aplicando o `SMOTE` mostraram-se muito mais assertivos nas valida√ß√µes do modelo. O **"RandomForest SMOTE"** apresentou:
    - Capacidade de generaliza√ß√£o
    - Melhor detec√ß√£o da classe positiva
    - Maior acur√°cia no teste real

O modelo agora √© excelente em identificar **'N√£o pacientes'**. Dos 33 reais, ele acertou 30 (Verdadeiros Negativos) e errou apenas 3 (Falsos Positivos).

No entanto, o custo dessa melhoria foi que o modelo agora erra mais na classe **'Paciente'**. Dos 83 reais, ele acertou 60 (Verdadeiros Positivos) e errou 23 (Falsos Negativos).

Em caso de evolu√ß√£o futura deste modelo, uma nova estrat√©gia seria revalidar os hiperpar√¢metros.

| Modelo           | Acur√°cia | F1-Score | CV Score |
|------------------|----------|----------|----------|
|RandomForest SMOTE| 0.801724 | 0.843537 | 0.734239 |

Com base na tabela dos resultados finais, o modelo `RandomForest` com `SMOTE` apresenta o melhor desempenho geral, alcan√ßando a maior acur√°cia e o maior score de valida√ß√£o cruzada.
