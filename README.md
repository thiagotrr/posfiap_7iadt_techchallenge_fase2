# üèÜ Tech Challenge Fase 2 - P√≥s Tech IA para Devs (posfiap_7iadt_techchallenge_fase2)

## üéØ Projeto Fase 2: Otimiza√ß√£o de Modelos de Diagn√≥stico
O hospital precisa melhorar a precis√£o e efici√™ncia dos modelos de diagn√≥stico desenvolvidos na Fase 1. O desafio √© utilizar algoritmos gen√©ticos para otimizar os hiperpar√¢metros desses modelos, al√©m de incorporar capacidades iniciais de processamento de linguagem natural por meio de LLMs para melhorar a interpretabilidade dos resultados para os profissionais de sa√∫de.

## üõ†Ô∏è Instala√ß√£o e execu√ß√£o

Este projeto utiliza [uv](https://docs.astral.sh/uv/guides/install-python/) ao inv√©s de pip devido ao framework [CrewAI](https://docs.crewai.com/), que requer gerenciamento de depend√™ncias mais eficiente.

### Pr√©-requisitos
1. Instalar o [uv](https://docs.astral.sh/uv/guides/install-python/)
2. Fazer o clone do reposit√≥rio:
   ```bash
   git clone <URL_DO_REPOSITORIO>
   ```

### Instala√ß√£o
1. Instalar Python 3.12 usando uv:
   ```bash
   uv python install 3.12
   ```

2. Instalar as depend√™ncias do projeto:
   ```bash
   uv pip install -r requirements.txt
   ```

3. (Opcional) Configurar as API Keys para usar o endpoint `/predicao-llm`:
   - Crie um arquivo `.env` na raiz do projeto
   - Adicione as chaves de API dos modelos que deseja usar:
     ```
     OPENAI_API_KEY=sua-chave-openai-aqui
     GROQ_API_KEY=sua-chave-groq-aqui
     GOOGLE_API_KEY=sua-chave-google-aqui
     ```
   - **Modelos dispon√≠veis e onde obter as API Keys:**
     - `openai/gpt-4o-mini`: [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)
     - `groq/llama-3.3-70b-versatile`: [https://console.groq.com/keys](https://console.groq.com/keys)
     - `google/gemini-3-flash-preview`: [https://aistudio.google.com/app/api-keys](https://aistudio.google.com/app/api-keys)
   - **Nota**: O endpoint `/predicao-llm` funciona sem as API keys, retornando uma mensagem padr√£o baseada nos dados do paciente. As API keys s√£o necess√°rias para gerar considera√ß√µes cl√≠nicas mais detalhadas usando os modelos de LLM.

### Execu√ß√£o
A partir da raiz do projeto, executar:
```bash
uv run python main.py
```

### Acessar a API
No browser, acessar:
- **Swagger UI**: [http://localhost:8181/docs](http://localhost:8181/docs)
- **OpenAPI JSON**: [http://localhost:8181/openapi.json](http://localhost:8181/openapi.json)

## ‚ú® Features Projeto Fase 2

Este projeto expande as capacidades do modelo de diagn√≥stico da Fase 1, introduzindo novas funcionalidades para treinamento, otimiza√ß√£o e rastreabilidade.

### üöÄ Treinamento e Otimiza√ß√£o do Modelo

- **Treinamento via API**: Execute o treinamento de um novo modelo `RandomForest` com `SMOTE` a qualquer momento atrav√©s do endpoint `/treinar_modelo`.
- **Otimiza√ß√£o com Algoritmo Gen√©tico**: Utilize o endpoint `/otimizar_modelo` para otimizar os hiperpar√¢metros do modelo. O processo utiliza um algoritmo gen√©tico para encontrar a melhor combina√ß√£o de par√¢metros, maximizando a performance.

### üîó Identificador √önico e Rastreabilidade

- Cada processo de **treinamento** ou **otimiza√ß√£o** gera um **identificador √∫nico hexadecimal**.
- Esse `id` cria um v√≠nculo direto e inequ√≠voco entre o **modelo treinado** (arquivo `.joblib`) e seu respectivo **arquivo de log**, garantindo total rastreabilidade dos artefatos gerados.

### ‚¨áÔ∏è Download de Artefatos

- **Acesso direto aos modelos e logs**: Ap√≥s o treinamento ou otimiza√ß√£o, utilize os endpoints `/modelo/{id_hex}` e `/log/{id_hex}` para baixar os arquivos gerados.
- Facilita a an√°lise de performance, o reuso de modelos e a auditoria do processo.

## ‚è™ Recap Fase 1
### üìä Dataset: Indian Liver Patient Dataset
A morte por cirrose hep√°tica continua a aumentar, devido ao aumento nas taxas de consumo de √°lcool, infec√ß√µes cr√¥nicas por hepatite e doen√ßas hep√°ticas relacionadas √† obesidade. Apesar da alta mortalidade dessa doen√ßa, as doen√ßas do f√≠gado n√£o afetam todas as subpopula√ß√µes de forma igual. A detec√ß√£o precoce da patologia √© determinante para o desfecho dos pacientes, mas as pacientes do sexo feminino parecem ser marginalizadas quando se trata do diagn√≥stico precoce de doen√ßas hep√°ticas.

O conjunto de dados √© composto por 584 registros de pacientes coletados no nordeste de Andhra Pradesh, na √çndia. A tarefa de predi√ß√£o consiste em determinar se um paciente sofre de doen√ßa hep√°tica com base em informa√ß√µes sobre diversos marcadores bioqu√≠micos, incluindo albumina e outras enzimas necess√°rias para o metabolismo.

### üß† Modelo Final: Random Forest com SMOTE

**Link do Notebook**: [Google Colab](https://colab.research.google.com/drive/1hcM9gq6GKSIyd4yXzhrtj6E1O54fqEPE?usp=sharing) üìù

Considerando a finalidade acad√™mica, e sabedores da sensibilidade em modelos voltados para √°rea de sa√∫de, tentamos duas √∫ltimas a√ß√µes:
    - Aplicar o `SMOTE` com objetivo de mitigar o desbalanceamento das classes.
    - Utilizar o `StratifiedKFold`, que performa melhor com dados bin√°rios.

### üìà Conclus√µes Fase 1
Os resultados aplicando o `SMOTE` mostraram-se muito mais assertivos nas valida√ß√µes do modelo. O **"RandomForest SMOTE"** apresentou:
    - Capacidade de generaliza√ß√£o
    - Melhor detec√ß√£o da classe positiva
    - Maior acur√°cia no teste real

O modelo agora √© excelente em identificar **'N√£o pacientes'**. Dos 33 reais, ele acertou 30 (Verdadeiros Negativos) e errou apenas 3 (Falsos Positivos).

No entanto, o custo dessa melhoria foi que o modelo agora erra mais na classe **'Paciente'**. Dos 83 reais, ele acertou 60 (Verdadeiros Positivos) e errou 23 (Falsos Negativos).

Em caso de evolu√ß√£o futura deste modelo, uma nova estrat√©gia seria revalidar os hiperpar√¢metros.

| Modelo           | Acur√°cia | F1-Score | CV Score |
|------------------|----------|----------|----------|
|RandomForest SMOTE| 0.801724 | 0.843537 | 0.734239 |

Com base na tabela dos resultados finais, o modelo `RandomForest` com `SMOTE` apresenta o melhor desempenho geral, alcan√ßando a maior acur√°cia e o maior score de valida√ß√£o cruzada.
